

https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/
为什么是隐藏层的循环，而不是输入层的循环

https://blog.csdn.net/qq_23225317/article/details/77834890 
就上面这个人讲明白了

http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/
上面的这个教程真的是太棒了

https://blog.csdn.net/zhaojc1995/article/details/80572098
讲到了 LSTM

LSTM 讲的较好的一篇博客：
http://colah.github.io/posts/2015-08-Understanding-LSTMs/

教我写 RNN
http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/
